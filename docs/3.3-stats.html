<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.3 Ймовірність у статистиці | Вступ до Екології Угруповань</title>
  <meta name="description" content="Непідручник" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="3.3 Ймовірність у статистиці | Вступ до Екології Угруповань" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Непідручник" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.3 Ймовірність у статистиці | Вступ до Екології Угруповань" />
  
  <meta name="twitter:description" content="Непідручник" />
  

<meta name="author" content="Олексій Дубовик" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="3.2-matrices.html"/>
<link rel="next" href="3.4-pdf-pmf.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Вступ до Екології Угруповань</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Вітання</a></li>
<li class="chapter" data-level="" data-path="передмова.html"><a href="передмова.html"><i class="fa fa-check"></i>Передмова</a>
<ul>
<li class="chapter" data-level="0.0.1" data-path="передмова.html"><a href="передмова.html#about-author"><i class="fa fa-check"></i><b>0.0.1</b> Трішки про автора</a></li>
<li class="chapter" data-level="0.0.2" data-path="передмова.html"><a href="передмова.html#whythiswork"><i class="fa fa-check"></i><b>0.0.2</b> Навіщо ця робота</a></li>
<li class="chapter" data-level="0.0.3" data-path="передмова.html"><a href="передмова.html#more-about-author"><i class="fa fa-check"></i><b>0.0.3</b> Ще трішки про автора</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="подяки.html"><a href="подяки.html"><i class="fa fa-check"></i>Подяки</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Вступ</a>
<ul>
<li class="chapter" data-level="1.0.1" data-path="1-introduction.html"><a href="1-introduction.html#community-def"><i class="fa fa-check"></i><b>1.0.1</b> Екологічне угруповання</a></li>
<li class="chapter" data-level="1.0.2" data-path="1-introduction.html"><a href="1-introduction.html#comm-ecol-today"><i class="fa fa-check"></i><b>1.0.2</b> Екологія угруповань сьогодні</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-about-book.html"><a href="2-about-book.html"><i class="fa fa-check"></i><b>2</b> Про книгу</a>
<ul>
<li class="chapter" data-level="2.0.1" data-path="2-about-book.html"><a href="2-about-book.html#readme"><i class="fa fa-check"></i><b>2.0.1</b> Дисклеймер</a></li>
<li class="chapter" data-level="2.1" data-path="2.1-how-built.html"><a href="2.1-how-built.html"><i class="fa fa-check"></i><b>2.1</b> Як побудована ця книга</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-expect.html"><a href="2.2-expect.html"><i class="fa fa-check"></i><b>2.2</b> Чого чекати від цієї книги</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-expected.html"><a href="2.3-expected.html"><i class="fa fa-check"></i><b>2.3</b> Чого ця книга чекає від читача</a></li>
<li class="chapter" data-level="2.4" data-path="2.4-notexpect.html"><a href="2.4-notexpect.html"><i class="fa fa-check"></i><b>2.4</b> На що не варто розраховувати</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-numerical-ecology.html"><a href="3-numerical-ecology.html"><i class="fa fa-check"></i><b>3</b> Базові математичні підходи в екології</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-algebra.html"><a href="3.1-algebra.html"><i class="fa fa-check"></i><b>3.1</b> Математична пам’ятка</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="3.1-algebra.html"><a href="3.1-algebra.html#дроби"><i class="fa fa-check"></i><b>3.1.1</b> Дроби</a></li>
<li class="chapter" data-level="3.1.2" data-path="3.1-algebra.html"><a href="3.1-algebra.html#математичні-символи"><i class="fa fa-check"></i><b>3.1.2</b> Математичні символи</a></li>
<li class="chapter" data-level="3.1.3" data-path="3.1-algebra.html"><a href="3.1-algebra.html#нерівності"><i class="fa fa-check"></i><b>3.1.3</b> Нерівності</a></li>
<li class="chapter" data-level="3.1.4" data-path="3.1-algebra.html"><a href="3.1-algebra.html#ступені"><i class="fa fa-check"></i><b>3.1.4</b> Ступені</a></li>
<li class="chapter" data-level="3.1.5" data-path="3.1-algebra.html"><a href="3.1-algebra.html#ряди-чисел"><i class="fa fa-check"></i><b>3.1.5</b> Ряди чисел</a></li>
<li class="chapter" data-level="3.1.6" data-path="3.1-algebra.html"><a href="3.1-algebra.html#ступені-арифметичних-операцій"><i class="fa fa-check"></i><b>3.1.6</b> Ступені арифметичних операцій</a></li>
<li class="chapter" data-level="3.1.7" data-path="3.1-algebra.html"><a href="3.1-algebra.html#лінійні-та-поліноміальні-функції"><i class="fa fa-check"></i><b>3.1.7</b> Лінійні та поліноміальні функції</a></li>
<li class="chapter" data-level="3.1.8" data-path="3.1-algebra.html"><a href="3.1-algebra.html#logs"><i class="fa fa-check"></i><b>3.1.8</b> Логарифми</a></li>
<li class="chapter" data-level="3.1.9" data-path="3.1-algebra.html"><a href="3.1-algebra.html#поширені-математичні-функції"><i class="fa fa-check"></i><b>3.1.9</b> Поширені математичні функції</a></li>
<li class="chapter" data-level="3.1.10" data-path="3.1-algebra.html"><a href="3.1-algebra.html#властивості-сум"><i class="fa fa-check"></i><b>3.1.10</b> Властивості сум</a></li>
<li class="chapter" data-level="3.1.11" data-path="3.1-algebra.html"><a href="3.1-algebra.html#властивості-добутків"><i class="fa fa-check"></i><b>3.1.11</b> Властивості добутків</a></li>
<li class="chapter" data-level="3.1.12" data-path="3.1-algebra.html"><a href="3.1-algebra.html#диференціювання"><i class="fa fa-check"></i><b>3.1.12</b> Диференціювання</a></li>
<li class="chapter" data-level="3.1.13" data-path="3.1-algebra.html"><a href="3.1-algebra.html#інтегрування"><i class="fa fa-check"></i><b>3.1.13</b> Інтегрування</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3.2-matrices.html"><a href="3.2-matrices.html"><i class="fa fa-check"></i><b>3.2</b> Лінійна алгебра</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-matrices.html"><a href="3.2-matrices.html#визначення-матриці"><i class="fa fa-check"></i><b>3.2.1</b> Визначення матриці</a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-matrices.html"><a href="3.2-matrices.html#трансформації-матриць"><i class="fa fa-check"></i><b>3.2.2</b> Трансформації матриць</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-matrices.html"><a href="3.2-matrices.html#операції-над-матрицями"><i class="fa fa-check"></i><b>3.2.3</b> Операції над матрицями</a></li>
<li class="chapter" data-level="3.2.4" data-path="3.2-matrices.html"><a href="3.2-matrices.html#детермінант-власні-вектори-та-власне-значення"><i class="fa fa-check"></i><b>3.2.4</b> Детермінант, власні вектори, та власне значення</a></li>
<li class="chapter" data-level="3.2.5" data-path="3.2-matrices.html"><a href="3.2-matrices.html#matrices_art"><i class="fa fa-check"></i><b>3.2.5</b> Геометричний зміст матриць</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-stats.html"><a href="3.3-stats.html"><i class="fa fa-check"></i><b>3.3</b> Ймовірність у статистиці</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-stats.html"><a href="3.3-stats.html#prob"><i class="fa fa-check"></i><b>3.3.1</b> Ймовірність</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-stats.html"><a href="3.3-stats.html#bayes"><i class="fa fa-check"></i><b>3.3.2</b> Теорема Баєса</a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-stats.html"><a href="3.3-stats.html#mle"><i class="fa fa-check"></i><b>3.3.3</b> Правдоподібність</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-pdf-pmf.html"><a href="3.4-pdf-pmf.html"><i class="fa fa-check"></i><b>3.4</b> Розподіли ймовірності</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3.4-pdf-pmf.html"><a href="3.4-pdf-pmf.html#pdfs"><i class="fa fa-check"></i><b>3.4.1</b> Функції розподілу ймовірності</a></li>
<li class="chapter" data-level="3.4.2" data-path="3.4-pdf-pmf.html"><a href="3.4-pdf-pmf.html#bars"><i class="fa fa-check"></i><b>3.4.2</b> Опис розподілу змінної (описова статистика)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-basic-hypotheses.html"><a href="3.5-basic-hypotheses.html"><i class="fa fa-check"></i><b>3.5</b> Тестування гіпотез</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="3.5-basic-hypotheses.html"><a href="3.5-basic-hypotheses.html#hypothesis"><i class="fa fa-check"></i><b>3.5.1</b> Статистична гіпотеза</a></li>
<li class="chapter" data-level="3.5.2" data-path="3.5-basic-hypotheses.html"><a href="3.5-basic-hypotheses.html#nulldistr"><i class="fa fa-check"></i><b>3.5.2</b> Нульовий розподіл</a></li>
<li class="chapter" data-level="3.5.3" data-path="3.5-basic-hypotheses.html"><a href="3.5-basic-hypotheses.html#pval"><i class="fa fa-check"></i><b>3.5.3</b> Тестування гіпотез</a></li>
<li class="chapter" data-level="3.5.4" data-path="3.5-basic-hypotheses.html"><a href="3.5-basic-hypotheses.html#paradigms"><i class="fa fa-check"></i><b>3.5.4</b> Парадигми статистичного аналізу</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-stat-models.html"><a href="3.6-stat-models.html"><i class="fa fa-check"></i><b>3.6</b> Експеримент і модель</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="3.6-stat-models.html"><a href="3.6-stat-models.html#pseudoreplication"><i class="fa fa-check"></i><b>3.6.1</b> Експериментальний дизайн та псевдореплікація</a></li>
<li class="chapter" data-level="3.6.2" data-path="3.6-stat-models.html"><a href="3.6-stat-models.html#regression"><i class="fa fa-check"></i><b>3.6.2</b> Дані та проблема моделювання</a></li>
<li class="chapter" data-level="3.6.3" data-path="3.6-stat-models.html"><a href="3.6-stat-models.html#aic"><i class="fa fa-check"></i><b>3.6.3</b> Парсимонійна модель та вибір моделі</a></li>
<li class="chapter" data-level="3.6.4" data-path="3.6-stat-models.html"><a href="3.6-stat-models.html#prcomp"><i class="fa fa-check"></i><b>3.6.4</b> Багатовимірна статистика</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="3.7-infer.html"><a href="3.7-infer.html"><i class="fa fa-check"></i><b>3.7</b> Передбачення, умовивід, та валідація</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="3.7-infer.html"><a href="3.7-infer.html#inference"><i class="fa fa-check"></i><b>3.7.1</b> Статистичний умовивід і обґрунтоване передбачення</a></li>
<li class="chapter" data-level="3.7.2" data-path="3.7-infer.html"><a href="3.7-infer.html#crossval"><i class="fa fa-check"></i><b>3.7.2</b> Крос-валідація</a></li>
<li class="chapter" data-level="3.7.3" data-path="3.7-infer.html"><a href="3.7-infer.html#bias-variance"><i class="fa fa-check"></i><b>3.7.3</b> Компроміс між упередженням та варіацією</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-popeco.html"><a href="4-popeco.html"><i class="fa fa-check"></i><b>4</b> Початки популяційної екології</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-species.html"><a href="4.1-species.html"><i class="fa fa-check"></i><b>4.1</b> Вид</a></li>
<li class="chapter" data-level="4.2" data-path="4.2-population.html"><a href="4.2-population.html"><i class="fa fa-check"></i><b>4.2</b> Популяція</a></li>
<li class="chapter" data-level="4.3" data-path="4.3-metapopulation.html"><a href="4.3-metapopulation.html"><i class="fa fa-check"></i><b>4.3</b> Метапопуляція</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-pop-factors.html"><a href="4.4-pop-factors.html"><i class="fa fa-check"></i><b>4.4</b> Чинники, що впливають на популяції</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-intraspecific.html"><a href="4.5-intraspecific.html"><i class="fa fa-check"></i><b>4.5</b> Внутрішньовидові взаємодії</a></li>
<li class="chapter" data-level="4.6" data-path="4.6-pop-dynamics.html"><a href="4.6-pop-dynamics.html"><i class="fa fa-check"></i><b>4.6</b> Динаміка та стабільність</a></li>
<li class="chapter" data-level="4.7" data-path="4.7-Leslie-matrix.html"><a href="4.7-Leslie-matrix.html"><i class="fa fa-check"></i><b>4.7</b> Матриці Леслі</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-foundations.html"><a href="5-foundations.html"><i class="fa fa-check"></i><b>5</b> Фундаментальні поняття екології</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-niche.html"><a href="5.1-niche.html"><i class="fa fa-check"></i><b>5.1</b> Екологічна ніша</a></li>
<li class="chapter" data-level="5.2" data-path="5.2-food-chain.html"><a href="5.2-food-chain.html"><i class="fa fa-check"></i><b>5.2</b> Трофічні ланцюги</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-food-webs.html"><a href="5.3-food-webs.html"><i class="fa fa-check"></i><b>5.3</b> Трофічні мережі</a></li>
<li class="chapter" data-level="5.4" data-path="5.4-keystones.html"><a href="5.4-keystones.html"><i class="fa fa-check"></i><b>5.4</b> Ключові види</a></li>
<li class="chapter" data-level="5.5" data-path="5.5-succession.html"><a href="5.5-succession.html"><i class="fa fa-check"></i><b>5.5</b> Сукцесія та клімакс</a></li>
<li class="chapter" data-level="5.6" data-path="5.6-life-history.html"><a href="5.6-life-history.html"><i class="fa fa-check"></i><b>5.6</b> Історія життя</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-detectability.html"><a href="5.7-detectability.html"><i class="fa fa-check"></i><b>5.7</b> Ймовірність детекції</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-interspecific.html"><a href="6-interspecific.html"><i class="fa fa-check"></i><b>6</b> Міжвидові взаємодії</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-relationships.html"><a href="6.1-relationships.html"><i class="fa fa-check"></i><b>6.1</b> Типи міжвидових зв’язків</a></li>
<li class="chapter" data-level="6.2" data-path="6.2-rstar.html"><a href="6.2-rstar.html"><i class="fa fa-check"></i><b>6.2</b> Теорія поділу ресурсів</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-cascade.html"><a href="6.3-cascade.html"><i class="fa fa-check"></i><b>6.3</b> Трофічні каскади</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-comecol.html"><a href="7-comecol.html"><i class="fa fa-check"></i><b>7</b> Екологічні угруповання</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-sad.html"><a href="7.1-sad.html"><i class="fa fa-check"></i><b>7.1</b> Структура угруповання</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-sad-model.html"><a href="7.2-sad-model.html"><i class="fa fa-check"></i><b>7.2</b> Моделі розподілів чисельності</a></li>
<li class="chapter" data-level="7.3" data-path="7.3-diversity.html"><a href="7.3-diversity.html"><i class="fa fa-check"></i><b>7.3</b> Різноманіття</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-similarity.html"><a href="7.4-similarity.html"><i class="fa fa-check"></i><b>7.4</b> Подібність угруповань</a></li>
<li class="chapter" data-level="7.5" data-path="7.5-fd.html"><a href="7.5-fd.html"><i class="fa fa-check"></i><b>7.5</b> Функціональне й філогенетичне різноманіття</a></li>
<li class="chapter" data-level="7.6" data-path="7.6-islands.html"><a href="7.6-islands.html"><i class="fa fa-check"></i><b>7.6</b> Острівна біогеографія</a></li>
<li class="chapter" data-level="7.7" data-path="7.7-env-filter.html"><a href="7.7-env-filter.html"><i class="fa fa-check"></i><b>7.7</b> Середовищне фільтрування</a></li>
<li class="chapter" data-level="7.8" data-path="7.8-untb.html"><a href="7.8-untb.html"><i class="fa fa-check"></i><b>7.8</b> Нейтральна теорія біорізноманіття</a></li>
<li class="chapter" data-level="7.9" data-path="7.9-rarefaction.html"><a href="7.9-rarefaction.html"><i class="fa fa-check"></i><b>7.9</b> Рарефакція та екстраполяція</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="післяслово.html"><a href="післяслово.html"><i class="fa fa-check"></i>Післяслово</a></li>
<li class="chapter" data-level="" data-path="контакти-автора.html"><a href="контакти-автора.html"><i class="fa fa-check"></i>Контакти автора</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Вступ до Екології Угруповань</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stats" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Ймовірність у статистиці<a href="3.3-stats.html#stats" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Наступні розділи не стосуватимуться різноманітних статистичних тестів, адже їх існує безліч. Варто розуміти, що не існує універсального рецепту до статистичного аналізу даних, а формулювання на кшталт “зробити якусь статистику для моїх даних” є ґрунтовно помилковим. Підходи до статистичного аналізу завжди випливають від дослідницького питання і адекватно поставлених гіпотез, а недалеким від правди є твердження, що для кожного дослідження є свій аналіз.</p>
<p>Критичним є розуміння понять, котрими оперує статистичний аналіз і котрі використовують всілякі статистичні тести. В наступних розділах буде описано ймовірність як підґрунтя статистичного аналізу (цей розділ), <a href="3.4-pdf-pmf.html#pdf-pmf">розподіли ймовірності</a>, <a href="3.5-basic-hypotheses.html#basic-hypotheses">тестування гіпотез</a>, <a href="3.6-stat-models.html#stat-models">поняття статистичних моделей</a>, та <a href="3.7-infer.html#infer">використання статистики для умовиводу та передбачення</a>.</p>
<div id="prob" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Ймовірність<a href="3.3-stats.html#prob" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Теорія ймовірності може видатись інтуїтивно зрозумілою до певної міри. Центральним поняттям її є, звісно, <strong>ймовірність</strong> (<em>probability</em>), для розуміння котрої необхідно окреслити поняття <strong>випадкового експерименту</strong> (<em>trial</em>) і <strong>випадкової події</strong> (<em>event</em>).</p>
<p>Випадковий експеримент є передмовою випадкової події. Наприклад, аби випав аверс, монету необхідно підкинути. Підкидання монети є випадковим експериментом, котрий може призвести до однієї із двох можливих випадкових подій: <strong>(1)</strong> випадає аверс, або <strong>(2)</strong> випадає реверс. Якщо ж монету не підкинути, то не станеться й випадкова подія.</p>
<p>Приклад монети завжди є доволі зручним, адже він інтуїтивний, простий, і зрозумілий. Очевидно, випадкові експерименти можуть бути набагато складнішими, а кількість альтернативних результуючих подій може бути незліченною.</p>
<p>У прикладі із монетою питання полягає в тому, яка є ймовірність події <strong>(1)</strong>, тобто випадання аверсу, або події <strong>(2)</strong>, себто випадання реверсу. Інтуїтивною відповіддю буде “50-на-50”, але це не є правильною відповіддю, адже ми не можемо знати це непевне. Що, наприклад, якщо вага монети незбалансована? Аби знайти відповідь на це питання, найпростішим підходом буде підкинути монетку безкінечну кількість разів і порахувати частоту випадання, скажімо, аверсу. Ця частота і буде ймовірністю.</p>
<p>Звісно, в реальності неможливо підкинути монету безліч разів, тому таке чисельне визначення ймовірності є суто теоретичним. Однак, якщо провести експеримент багато разів, це дозволить знайти приблизне значення шуканої ймовірності. Скоріш за все, воно буде близьким до <span class="math inline">\(P(аверс) \approx 0.5\)</span>. А якщо читач має добре підґрунтя в статистиці, то навіть знайдеться тест для перевірки чесності монети: звісно, що після багатьох підкидань спостережена частота аверсу може відрізнятись від <span class="math inline">\(0.5\)</span> і становити, скажімо, <span class="math inline">\(0.498\)</span>. Так от, різниця <span class="math inline">\(0.5 - 0.498 = 0.002\)</span> за певного розміру вибірки буде значущою (тобто монета нечесна) або ні.</p>
<p>Очевидно, що ймовірність не може бути від’ємною, а найменше її значення становить <span class="math inline">\(0\)</span>. В такому випадку (<span class="math inline">\(P = 0\)</span>), випадкова подія не станеться навіть якщо випадковий експеримент буде відтворено безкінечну кількість разів. З іншого боку, ймовірність <span class="math inline">\(1\)</span> вказує на те, що випадкова подія станеться за кожного експерименту. Зазвичай, значення ймовірності знаходиться десь в інтервалі між цими двома екстремальними значеннями.</p>
<p>В багатьох випадках, не потрібно мати монету в руках аби зрозуміти ймовірності подій. Щоправда, системи таких подій часто є набагато складнішими. Наприклад, що якщо є дві монетки? Простір можливих подій тоді стає більшим, адже тепер може випасти два аверса, два реверса, або аверс і реверс. Якими є ймовірності цих подій, якщо підкидання монети є незалежним від підкидання іншої монети, і обидві монети є чесними (тобто очікувана ймовірність випадіння аверсу дорівнює <span class="math inline">\(0.5\)</span>)?</p>
<p>Оскільки монет є дві, існує декілька сценаріїв розвитку подій: <strong>(1)</strong> монета 1 випадає на аверс і монета 2 випадає на аверс, <strong>(2)</strong> монета 1 випадає на аверс і монета 2 випадає на реверс, <strong>(3)</strong> монета 1 випадає на реверс і монета 2 випадає на аверс, або <strong>(4)</strong> монета 1 випадає на реверс і монета 2 випадає на реверс. То якими є ймовірності трьох (аверс-аверс, реверс-реверс, аверс-реверс) випадкових подій згаданих вище?<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p>Ми бачимо як проста монетка може генерувати доволі складні ймовірнісні ситуації – а що ж тоді буде зі звичайними гральними кубиками? А якщо ми візьмемо до уваги щось складніше на кшталт набору кубиків до Підземелля й Драконів із їх 4-, 6-, 10-, 12-, і 20-гранними костями? В таких випадках <em>простори ймовірності</em> стають дедалі складнішими. І всі ці випадки є <em>дискретними</em> (<em>discrete</em>), в яких будь-яку подію можна описати неподільним одиничним значенням (з підкидання монетки може випасти або аверс, або реверс – ми маємо тільки два можливих значення), на відміну від <em>неперевних, або континуальних</em> (<em>continuous</em>) змінних (які можна описати дійсними числами).</p>
<p>Що таке ймовірнісний простір? Строго кажучи, <strong>ймовірнісний простір</strong> (<em>probability space</em>) – це формальна модель випадкового експерименту. У випадку з одним підкиданням монетки, його можна поділити на наступні елементи:</p>
<ul>
<li><p><strong>простір елементарних подій</strong> (<span class="math inline">\(\Omega\)</span>, <em>sample space</em>) – множина, яка описує всі можливі варіанти випадкової події: <span class="math inline">\(\{аверс, реверс\}\)</span>;</p></li>
<li><p>асоційована <em>сигма-алгебра</em> (<span class="math inline">\(\sigma\)</span>, <em>event space</em>) – якщо простими словами, то це така множина, яка включає в себе всі можливі підмножини <span class="math inline">\(\Omega\)</span>;</p></li>
<li><p><strong>ймовірності подій</strong> (<span class="math inline">\(P\)</span>, <em>probability</em>) – визначені для елементарних подій значення ймовірностей, наприклад: <span class="math inline">\(P(аверс) = 0.5, P(реверс) = 0.5\)</span>.</p></li>
</ul>
<p>Для прикладу з монеткою асоційована сигма-алгебра <span class="math inline">\(\sigma = \{\{аверс\}, \{реверс\}, \{аверс, реверс\}, \{\emptyset\}\}\)</span>, і в повному вигляді ймовірності подій складатимуть <span class="math inline">\(P(аверс) = 0.5, P(реверс) = 0.5, P({аверс, реверс}) = 0, P(\emptyset) = 0\)</span>.</p>
<p><strong><em>Аксіоматично</em></strong>, ймовірність можна визначити наступним чином: для простору елементарних подій <span class="math inline">\(S\)</span> й асоційованої сигма-алгебри множин <span class="math inline">\(\mathbb{B}\)</span>, функція ймовірності <span class="math inline">\(P\)</span> із доменом <span class="math inline">\(\mathbb{B}\)</span> задовільняє наступні вимоги</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(P(A) \geq 0 \text{ } \forall \text{ } A \in \mathbb{B}\)</span> (тобто ймовірність будь-якої події <span class="math inline">\(A\)</span> в просторі елементарних подій більше або дорівнює нулю),</p></li>
<li><p><span class="math inline">\(P(S) = 1\)</span> (тобто ймовірність цілого простору подій дорівнює одиниці),</p></li>
<li><p>якщо cкінченні події <span class="math inline">\(A_1, A_2, A_3, \cdots \in \mathbb{B}\)</span> є взаємовиключними (<span class="math inline">\(A_i \cap A_j = \emptyset \forall i \neq j\)</span>), тоді <span class="math inline">\(P(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} P(A_i)\)</span> (тобто ймовірність всіх цих подій дорівнює сумі ймовірностей цих окремих подій).</p></li>
</ol>
<p>В такому випадку, уявімо наступне: (1) <span class="math inline">\(S = \{S_1, S_2, \cdots, \S_n\}\)</span>, (2) <span class="math inline">\(\mathbb{B}\)</span> – асоційована із <span class="math inline">\(S\)</span> сигма-алгебра, (3) <span class="math inline">\(p_1, p_2, \cdots, p_n\)</span> – не-негативні числа із сумою <span class="math inline">\(\sum_{i=1}^n p_i = 1\)</span>, і (4) для всякої події <span class="math inline">\(A \in \mathbb{B}\)</span> визначимо <span class="math inline">\(P(A) = \sum_{i:S_i \in A}(p_i)\)</span>. Тоді <span class="math inline">\(P\)</span> можна назвати ймовірнісною функцією визначеною в <span class="math inline">\(\mathbb{B}\)</span> якщо вона відповідає вимогам аксіоматичного визначення ймовірності (див. вище). Із такого визначення випливають наступні наслідки:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(\emptyset) = 0\)</span>: ймовірність нульової множини (тобто відсутності події) становить нуль, якщо монетку вже підкинуто, то станеться або аверс, або реверс;</li>
<li><span class="math inline">\(P(A) \leq 1\)</span>: ймовірність події не може бути більшою за одиницю;</li>
<li><span class="math inline">\(P(A^c) = 1 - P(A) \Leftrightarrow P(A) + P(A^c) = 1 \Leftrightarrow A \cup A^c = S\)</span>: ймовірність комплементу події зворотно пов’язана із ймовірністю цієї події (якщо ймовірність викинути аверс становить <span class="math inline">\(0.3\)</span>, то ймовірність комплементу – тобто не викинути аверс – становить <span class="math inline">\(1-0.3\)</span>);</li>
<li><span class="math inline">\(P(B \cap A^c) = P(B) - P(B\cap A)\)</span> (з цього моменту пояснювати вербально стає складніше, читачу варто побавитись із колами Ейлера аби уявити про що йдеться);</li>
<li><span class="math inline">\(P(B \cup A) = P(B) + P(A) - P(B\cap A)\)</span>;</li>
<li><span class="math inline">\(A \subset B\)</span>, <span class="math inline">\(P(A) \leq P(B)\)</span>;</li>
<li><span class="math inline">\(P(B \cap A) \geq P(B) + P(A) - 1\)</span>.</li>
</ol>
<p>Коли йдеться про ймовірності, дуже важливим моментом є <strong>незалежність подій</strong> (<em>independence</em>) і пов’язані поняття. Дві події, <span class="math inline">\(A\)</span> і <span class="math inline">\(B\)</span>, вважаються незалежними якщо <span class="math inline">\(P(A \cap B) = P(A) P(B)\)</span>. Якщо <span class="math inline">\(A \cap B = \emptyset\)</span>, тобто ці події не мають жодних спільних елементів в просторі елементарних подій, то такі події можна описати як <strong>взаємовиключні</strong> (<em>mutually exclusive</em>; наприклад, одне підкидання монетки). Скінченна множина подій є <strong>попарно незалежною</strong> (<em>pairwise independence</em>) якщо для всіх пар справджується наступне: <span class="math inline">\(P(A_i \cap A_j) = P(A_i)P(A_j)\)</span>. Якщо ж кожна подія в множині незалежна від будь-яких перетинів всіх інших подій: <span class="math inline">\(P(\cap_{j=1}^k A_{i_j}) = \prod_{j=1}^k P(A_{i_j})\)</span>, тоді такі події можна назвати <strong>взаємонезалежними</strong> (<em>mutually independent</em>).</p>
</div>
<div id="bayes" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Теорема Баєса<a href="3.3-stats.html#bayes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Уявімо дві події, <span class="math inline">\(A\)</span> і <span class="math inline">\(B\)</span>, котрі належать до <span class="math inline">\(S\)</span> (<span class="math inline">\(\{A, B\} \in S\)</span>), і, скажімо, <span class="math inline">\(P(B) &gt; 0\)</span>. Тоді ми можемо означити <strong>умовну ймовірність</strong> (<em>conditional probability</em>) події <span class="math inline">\(A\)</span> за того, що подія <span class="math inline">\(B\)</span> відбулась: <span class="math inline">\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)</span>. Це доволі нескладно осягнути інтуїтивно. Скажімо, ми підкидаємо дві чесні монетки по черзі: <span class="math inline">\(B\)</span> позначає випадіння аверса з першою монеткою, <span class="math inline">\(A\)</span> позначає другий аверс. В цілому експерименті може статись чотири різні варіанти: аверс-аверс, аверс-реверс, реверс-аверс, і реверс-реверс. Ймовірність пари “аверс-аверс” складає <span class="math inline">\(P(A \cap B) = 1/4\)</span>. Ймовірність просто викинути реверс із першою монеткою становить <span class="math inline">\(P(B) = 1/2\)</span>. Тоді якщо ми припустимо, що перша монетка поверне аверс, ймовірність того що й друга монетка випаде на аверс становить <span class="math inline">\(P(A | B) = \frac{1/4}{1/2} = 1/2\)</span>.</p>
<p>Якщо ми знаємо, що <span class="math inline">\(P(A)&gt;0\)</span>, тоді можна побачити що <span class="math inline">\(P(B|A) = \frac{P(B \cap A)}{P(A)} = \frac{P(A | B)P(B)}{P(A)}\)</span>. Отже, <span class="math inline">\(P(B|A)P(A)=P(A|B)P(B)=P(A \cap B)\)</span>. Якщо продовжувати бавитись із підстановками в цих рівняннях, то вийде що <span class="math inline">\(P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B|A) P(A)}{P(B)} = \frac{P(B|A)P(A}{P(B \cap A) + P(B \cap A^c)} = \frac{P(B|A)P(A)}{P(B|A) P(A) + P(B|A^c)P(A^c)}\)</span>, що зветься Баєсівським правилом умовних ймовірностей і призводить до <strong>теореми Баєса</strong> (<em>Bayes theorem</em>).</p>
<p>Уявімо що <span class="math inline">\(\{A_1, A_2, A_3, \cdots\}\)</span> є поділом простору <span class="math inline">\(S\)</span> (<span class="math inline">\(A_i \cap A_j = \emptyset \forall i \neq j\)</span>, <span class="math inline">\(\cup_{k=1}^{\infty} A_k = S\)</span>). Уявіть будь-яку множину <span class="math inline">\(B\)</span>. Тоді</p>
<p><span class="math display">\[P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{k=1}^{\infty}[P(B|A_k)P(A_k)]}\]</span></p>
<p>Певною мірою, цю теорему нескладно зрозуміти інтуїтивно, але іноді може видаватись навпаки. Для простого прикладу, уявімо що ми маємо список студентів з двох різних груп. В групі <span class="math inline">\(A\)</span> сумарно 80 студентів: 60 жінок і 20 чоловіків; в групі <span class="math inline">\(B\)</span> – 20 студентів, десятеро жінок і десятеро чоловіків. Ви обираєте випадкову особу із цих двох груп і бачите, що це чоловік. Які ймовірності того, що цей студент походить із певної групи? Ми бачимо що ймовірність обрати чоловіка з групи <span class="math inline">\(A\)</span> складає <span class="math inline">\(P(male|A) =  20/(60+20) = 1/4\)</span>, в той час як в групі <span class="math inline">\(B\)</span> – <span class="math inline">\(P(male|B) = 10/(20+20) = 1/2\)</span>. Але в той же час ймовірність обрати випадкову особу із групи <span class="math inline">\(A\)</span> становить <span class="math inline">\(P(A) = 80/(80+20) = 4/5\)</span>, в той час як з групи <span class="math inline">\(B\)</span> – <span class="math inline">\(P(B) = 20/(80+20) = 1/5\)</span>, і ми маємо врахувати ці ймовірності коли оцінюємо шукану ймовірність того, що наш студент походить із групи <span class="math inline">\(A\)</span>. Так, в цій групі небагато чоловіків, але й розмір групи великий, тож випадкова особа набагато ймовірніше потрапила із групи <span class="math inline">\(A\)</span>! Але навіть без оцінки всіх цих дрібних ймовірностей, у цілій вибірці сумарно <span class="math inline">\(30\)</span> чоловіків: <span class="math inline">\(20\)</span> походять із групи <span class="math inline">\(A\)</span>, <span class="math inline">\(10\)</span> – із групи <span class="math inline">\(B\)</span>. Отже, ймовірність обрати чоловіка із групи <span class="math inline">\(A\)</span> становитиме <span class="math inline">\(20/30\)</span>, із групи <span class="math inline">\(B\)</span> – <span class="math inline">\(10/30\)</span>. Ймовірності так само співпадають, наприклад, <span class="math inline">\(P(A|male) = \frac{P(male|A)P(A)}{P(male|A)P(A) + P(male|B)P(B)} = \frac{(20/80) \cdot (80/100)}{(20/80) \cdot (80/100) + (10/20) \cdot (20/100)} = \frac{0.2}{0.2+0.1}=2/3\)</span>.</p>
<p>Хоча й ця теорема не здається надто складною, вона надає цікавий погляд на процеси пізнання світу й <a href="3.5-basic-hypotheses.html#paradigms">статистичний умовивід</a>. Одним із знаменитих прикладів є наступний уявний експеримент. Пацієнт здав кров на аналіз на якусь відносно непоширену хворобу (на неї хворіють, скажімо, <span class="math inline">\(1\%\)</span> популяції), і, на жаль, отримав позитивний результат. Чи це означає що наш пацієнт дійсно хворий на цю хворобу? Адже тести можуть помилятися. Відповідь, звісно, залежить від конкретних чисел, але, в цілому, нашому пацієнтові рано хнюпити носа. Скажімо, наш тест має точність <span class="math inline">\(95\%\)</span> в позитивних випадках (тобто із <span class="math inline">\(20\)</span> хворих пацієнтів один отримає негативний тест – отже, частота хибно-негативних результатів складає <span class="math inline">\(5\%\)</span>). Мало того, зрідка тест може помилятись і з негативними пацієнтами: наприклад, кожен десятий здоровий пацієнт отримає хибно-позитивний результат (частота хибно-позитивних результатів становить <span class="math inline">\(10\%\)</span>). Відтак, як би ситуація погано не виглядала для нашого пацієнта, яка ситуація є більш ймовірною: <strong><em>(1)</em></strong> пацієнт належить до <span class="math inline">\(1\%\)</span> всієї популяції і дійсно хворіє, тож тест надав істинний результат (ймовірність якого <span class="math inline">\(95\%\)</span>), або <strong><em>(2)</em></strong> пацієнт належить до <span class="math inline">\(99\%\)</span> популяції і є здоровим, а тест надав хибний результат (ймовірність чого <span class="math inline">\(10\%\)</span>)? Спробуйте застосувати теорему Баєса для оцінки цих постеріорних<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> ймовірностей цих двох сценаріїв. (Іноді мені й самому потрібно задуматись із тим, куди у формулі підставляти котрі числа, тож, мабуть, вирішення подібних задач вимагає практики). А життєвий урок із цієї задачі наступний: якою б не видавалась ймовірність події, потрібно завжди враховувати наявне пріорне знання.</p>
<p>Розберемо теорему на запчастини із цим прикладом. Уявімо весь наш простір ймовірностей, який представляє велику популяцію пацієнтів (наприклад, <span class="math inline">\(10000\)</span> людей). У ньому апріорна ймовірність того, що випадковий пацієнт здоровий, складає <span class="math inline">\(P(\text{здоровий}) = 0.99\)</span>, й, відповідно, <span class="math inline">\(P(\text{хворий}) = 0.01\)</span>. Із опису якості тесту на захворювання ми знаємо, що із сотні хворих людей п’ятеро отримають хибно-негативний результат: <span class="math inline">\(P(\text{негативний|хворий}) = 0.05 \Leftrightarrow P(\text{позитивний|хворий}) = 0.95\)</span>. Водночас, коли ми перевіряємо здорових людей із цим не надто якісним тестом, то <span class="math inline">\(P(\text{негативний|здоровий}) = 0.9 \Leftrightarrow P(\text{позитивний|здоровий}) = 0.1\)</span>. Ми можемо прикинути розподіл пацієнтів за класами в такій десятитисячній популяції:</p>
<ul>
<li><p><span class="math inline">\(10000 \times P(\text{здоровий}) = 10000 \times 0.99 = 9900\)</span> здорових людей, з яких</p>
<ul>
<li><p><span class="math inline">\(9900 \times P(\text{позитивний|здоровий}) = 9900 \times 0.1 = 990\)</span> отримало позитивний тест,</p></li>
<li><p><span class="math inline">\(9900 \times P(\text{негативний|здоровий}) = 9900 \times 0.9 = 8910\)</span> отримало негативний тест,</p></li>
</ul></li>
<li><p><span class="math inline">\(10000 \times P(\text{хворий}) = 10000 \times 0.01 = 100\)</span> хворих людей, з яких</p>
<ul>
<li><p><span class="math inline">\(100 \times P(\text{позитивний|хворий}) = 100 \times 0.95 = 95\)</span> отримало позитивний тест,</p></li>
<li><p><span class="math inline">\(100 \times P(\text{негативний|хворий}) = 100 \times 0.05 = 5\)</span> отримало негативний тест.</p></li>
</ul></li>
</ul>
<p>В цій популяції <span class="math inline">\(990 + 95 = 1080\)</span> отримало позитивний тест, але ми явно бачимо що із людей з позитивним тестом більше здорових, аніж хворих! Отож і нашому пацієнту є над чим задуматись коли навіть із позитивним тестом він набагато ймовірніше є здоровим, аніж хворим.</p>
<p>Отже, яка ймовірність того, що пацієнт із позитивним тестом є хворим? Запросто, <span class="math inline">\(95/1080 \approx 0.088\)</span>, в той час ймовірність що він здоровий становить <span class="math inline">\(990/1080 \approx 0.912\)</span>. Як бачимо, набагато простіше оперувати одиницями пацієнтів, хоча із канонічним застосуванням Баєсівської формули вийде ідентичний результат, ніби пацієнти поскорочувались в рівняннях. Наприклад,</p>
<p><span class="math display">\[
\begin{aligned}
  P(\text{здоровий|позитивний}) = \\
  \frac{[P(позитивний|здоровий)] P(здоровий)}{[P(позитивний|здоровий) P(здоровий) + P(позитивний|хворий) P(хворий)]} = \\
  \frac{[0.1] \cdot 0.99}{[0.1 \cdot 0.99 + 0.95 \cdot 0.01]} = 0.099/0.1085 \approx 0.912
\end{aligned}
\]</span></p>
</div>
<div id="mle" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Правдоподібність<a href="3.3-stats.html#mle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Іноді Баєсівське правило уявляють наступним чином:</p>
<p><span class="math display">\[\text{(постеріорна ймовірність)} = \frac{\text{[правдоподібність]} \times \text{(пріорна ймовірність)}}{\text{[свідчення]}}\]</span>
З попереднього розділу можна здогадатись що <strong>постеріорна ймовірність</strong> (<em>posterior</em>) – це ота шукана ймовірність події за наявного <strong>пріорного</strong> (<em>prior</em>) знання. В прикладі із попереднього підрозділу пріорною ймовірністю була ймовірність того, що пацієнт здоровий. Ця ймовірність відображала об’єктивну реальність незалежно від результатів тесту. <strong>Свідчення</strong> ще називають відособленою правдоподібністю (<em>marginal likelihood</em><a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>), і воно відповідає оцьому дивному значенню <span class="math inline">\(0.1085\)</span> із попереднього прикладу – найпростіший шлях то думати про це як про якесь нормалізуюче значення яке просто <em>треба</em>. У відображенні того прикладу із кількостями людей же те значення відповідало <span class="math inline">\(1080\)</span>-тьом нещасним, котрі отримали позитивний результат тесту. Але що таке <strong>правдоподібність</strong> (<em>likelihood</em>)?</p>
<p>В попередньому прикладі на питання “отримав позитивний тест, чи пора вмирать?” можна відповісти без повного вирішення через Баєсівське рівняння. В ситуації <strong>(1)</strong> можна просто перемножити <span class="math inline">\(P(\text{позитивний|здоровий})P(\text{здоровий}) = 0.1 \cdot 0.99 = 0.099\)</span>, а в <strong>(2)</strong> – <span class="math inline">\(P(\text{позитивний|хворий})P(\text{хворий}) = 0.95 \cdot 0.01 = 0.0095\)</span>. Оці два результуючі значення є правдоподібностями, які відповідають певним ситуаціям. В технічному сенсі, правдоподібність є ймовірністю, але ця ймовірність має зміст лише у визначених обмежених підпросторах події, тож про правдоподібність простіше думати як про якесь безрозмірне значення яке пропорційне ймовірності якоїсь події. У цьому прикладі, <span class="math inline">\(0.099 &gt; 0.0095\)</span>, отже, ситуація <strong>(1)</strong> майже вдесятеро більш правдоподібна за ситуацію <strong>(2)</strong>. Отже, шановний пацієнте, ні, ваш результат тесту за даного контексту ще не кінець світу.</p>
<p>Поняття правдоподібності дуже корисне в підборі параметрів моделі. Зазвичай, в статистиці задача аналізу вибірки полягає в оцінці якогось параметру, однак на цю задачу можна дивитись і з протилежного боку: як оцінити наскільки вибірка правдоподібна за певного параметру? Наприклад, уявіть результат багаторазового (скажімо, <span class="math inline">\(n = 10\)</span>) підкидання монетки як якийсь вектор (наприклад, <span class="math inline">\(X = \{H, T, H, T, T, T, H, H, T, T\}\)</span>, або ж якщо випадіння аверсу позначити як одиницю, то <span class="math inline">\(X = \{1, 0, 1, 0, 0, 0, 1, 1, 0, 0\}\)</span>). Окреме випадіння аверсу є подією із розподілу Бернулі (див. <a href="3.4-pdf-pmf.html#pdfs">наступний розділ</a>), яке описується ймовірністю одиночної події <span class="math inline">\(p\)</span> (у нашому випадку – яка ймовірність випадіння аверсу за одного підкидання?). Приймемо функцію розподілу ймовірності (знову ж, дивись нижче що то таке) за <span class="math inline">\(f(x) = p^x (1-p)^{1-x}\)</span> (<span class="math inline">\(x \in X\)</span>, тобто тут ми позначаємо окреме спостереження як <span class="math inline">\(x\)</span> і вибірку як <span class="math inline">\(X\)</span>), тоді функція правдоподібності відповідатиме виразу</p>
<p><span class="math display">\[\mathcal{L}(p|X) = \prod \limits_{i = 1}^n p^{x_i} (1 - p)^{1-x_i}\]</span>
Очевидно, що ця функція приймає на вхід якусь фіксовану вибірку <span class="math inline">\(X\)</span> і пробігає по всіх можливим значенням параметру <span class="math inline">\(p\)</span>. Помічаєте як змінився підхід? Параметр вибірки не виглядає як якесь фіксоване значення, а радше як рухома ціль. Наше ж завдання – це знайти таке значення <span class="math inline">\(p\)</span>, <span class="math inline">\(\hat{p}\)</span>, за якого функція правдоподібності буде мати найбільше значення. Тоді ми можемо вважати оцінку (<em>estimate</em>) <span class="math inline">\(\hat{p}\)</span> такою, за якої отримати нашу вибірку <span class="math inline">\(X\)</span> видається най-<em>правдоподібніше</em>. Це іноді може бути непростим завданням для вирішення рівнянь, й до того ж значення правдоподібності дуже маленькі, особливо для малих вибірок (тому що ми множимо якісь значення ймовірностей <span class="math inline">\(p \leq 1\)</span> знову і знову). Тут можна використати один простий трюк: взяти логарифм цілої функції. Це несуттєво вплине на пошук максимального значення функції, адже приріст логарифмованої функції завжди відбувається в тому ж напрямку, що й вихідної функції. І отож, ми можемо визначити функцію лог-правдоподібності:</p>
<p><span class="math display">\[\ln \mathcal{L}(p|X) = \ln \left( \prod \limits_{i = 1}^n p^{x_i} (1 - p)^{1-x_i} \right) = \ln p \sum \limits_{i=1}^n x_i + \ln (1-p) \sum \limits_{i=1}^n (1 - x_i)\]</span></p>
<p>Аби знайти максимум цієї функції, можна спробувати знайти таке значення, за якого похідна функції лог-правдоподібності становитиме нуль (тобто відсутність приросту функції – це має бути або її максимум, або її мінімум). Наразі немає необхідності влазити в подальші деталі розрахунків<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>, але після прирівняння похідної до нуля можна перебудувати рівняння таким чином, аби з одного боку рівняння було лише <span class="math inline">\(p\)</span>. Це рівняння відповідатиме оцінці максимальної правдоподібності, у нашому випадку,</p>
<p><span class="math display">\[\hat{p} = \frac{1}{n} \sum \limits_{i=1}^n x_i\]</span></p>
<p>Іронічно, у випадку розподілу Бернулі оцінка максимальної правдоподібності дорівнює середньому арифметичному, тож <span class="math inline">\(\hat{p} = 0.4\)</span> для нашої вибірки <span class="math inline">\(X = \{1, 0, 1, 0, 0, 0, 1, 1, 0, 0\}\)</span>.</p>
<p>Найпростіше застосування методу пошуку оцінщика (<em>estimator</em>) максимальної правдоподібності застосовується в подібних ситуаціях, коли існує припущення щодо функції розподілу ймовірності вибірки, який дозволяє розписати функцію правдоподібності і шукати її максимум. В таких випадках моделлю є вибірка, і ми шукаємо параметр розподілу, за якого ця вибірка є найбільш правдоподібною. В складніших ситуаціях моделлю може бути власне щось, що ми розуміємо під поняттям <a href="3.6-stat-models.html#stat-models">математичної моделі</a>, на кшталт регресії, а параметрів моделі може бути більш ніж один – і метод максимальної правдоподібності все одно працює… принаймні до моменту поки не вдасться знайти математика, котрий зможе аналітично знайти функцію лог-правдоподібності, взяти її похідну, і так далі.</p>
<p>Чи є правдоподібність ймовірністю? І так, і ні, і, скоріше, ні аніж так. Правдоподібність є <em>пропорційною</em> до ймовірності спостерігати змінну за певного значення параметру і є функцією цього параметру. Одна із вимог аксіоматичного визначення ймовірності каже, що інтеграл функції ймовірності повинен дорівнювати одиниці; у випадку правдоподібності як функції певного параметру, інтегрування цієї функції не завжди дорівнюватиме одиниці, відтак, за визначенням правдоподібність не є ймовірністю в таких випадках.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>Позначимо ймовірність випадання аверсу (A) або реверсу (R) на першій монеті як <span class="math inline">\(P(C_1 = A) = P(C_1 = R) = 0.5\)</span> і на другій монеті як <span class="math inline">\(P(C_2 = A) = P(C_2 = R) = 0.5\)</span>. Тоді <span class="math inline">\(P(A, A) = P(C_1 = A) \cdot P(C_2 =  A) = 0.5 \cdot 0.5 = 0.25\)</span>, <span class="math inline">\(P(R, R) = P(C_1 = R) \cdot P(C_2 =  R) = 0.5 \cdot 0.5 = 0.25\)</span>, і <span class="math inline">\(P(A, R) = P(C_1 = A) \cdot P(C_2 = R) + P(C_1 = R) \cdot P(C_2 = A) = 0.25 + 0.25 = 0.5\)</span>.<a href="3.3-stats.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Поширеними термінами в цій сфері є <strong>пріорна, або апріорна, ймовірність</strong> <span class="math inline">\(P(A)\)</span> (<em>prior</em>) – така, яку можна спостерігати до оновлення нашого знання (все одно які результати тесту, ми і так знаємо скільки хворих в популяції), та <strong>постеріорна, або апостеріорна, ймовірність</strong> <span class="math inline">\(P(A|B)\)</span> (<em>posterior</em>) – оновлена ймовірність події за умови нашого пріорного знання.<a href="3.3-stats.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Переклад українською суто з Вікіпедії, мені загалом не звучить.<a href="3.3-stats.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>…але якщо дуже треба, то похідну можна знайти як <span class="math inline">\(\frac{d \ln \mathcal{L} (p)}{d p} = \frac{\sum_{i=1}^n x_i}{p} - \frac{\sum_{i=1}^n (1 - x_i)}{1-p}\)</span>, яку прирівнюємо до нуля і розв’язуємо для <span class="math inline">\(p\)</span>: <span class="math inline">\(\frac{\sum_{i=1}^n x_i}{\hat{p}} = \frac{\sum_{i=1}^n (1 - x_i)}{1-\hat{p}}\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\frac{\hat{p}}{1 - p} = \frac{\sum_{i=1}^n x_i}{\sum_{i=1}^n (1 - x_i)}\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat{p} = (1 - \hat{p}) \frac{\sum_{i=1}^n x_i}{n - \sum_{i=1}^n x_i}\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat{p} (n - \sum_{i=1}^n x_i) = (1 - \hat{p}) \sum_{i=1}^n x_i = \sum_{i=1}^n x_i - \hat{p} \sum_{i=1}^n x_i\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat{p} (n - \sum_{i=1}^n x_i) + \hat{p} \sum_{i=1}^n x_i = \sum_{i=1}^n x_i\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(n\hat{p} = \sum_{i=1}^n x_i\)</span>, <span class="math inline">\(\hat{p} = \frac{\sum_{i=1}^n x_i}{n}\)</span>. Краса та й годі!<a href="3.3-stats.html#fnref19" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="3.2-matrices.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3.4-pdf-pmf.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
